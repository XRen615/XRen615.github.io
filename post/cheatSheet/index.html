<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.15" />

  <title>Python Data Engineering Cheat Sheet &middot; INCH2</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="http://xren615.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="http://xren615.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="http://xren615.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <link rel="alternate" type="application/rss+xml" title="INCH2" href="http://xren615.github.ioindex.xml" />

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="http://xren615.github.ioimg/favicon.ico" type="image/x-icon" />

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="http://xren615.github.io/">INCH<sup>2</sup></a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://xren615.github.io/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://xren615.github.io/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://xren615.github.io/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://xren615.github.ioindex.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
    </li>

    

    
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://500px.com/rubiconren" target="_blank"><i class="fa fa-500px fa-fw"></i>500px</a>
    </li>
    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/xinyuyangren" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/xren615" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

  </ul>
</div>


  <div class="pure-g">
  <div class="small-print pure-u-1 pure-u-md-1-1">
    <small>&copy; 2016. All rights reserved.</small>
  </div>
  <div class="small-print pure-u-1 pure-u-md-1-1">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Python Data Engineering Cheat Sheet</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>02 Mar 2017, 17:40</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://xren615.github.iotags/"></a>
    
  </div>
  
  

</div>

  

<p>By my experience, some frequent needed utilities in Python data scripts —— good to have it by hand when you facing puzzle.</p>

<h3 id="etl:f1e1a77f1615c44bf32d0a2ae6e592a4">ETL</h3>

<hr />

<pre><code>import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import pandas as pd
import seaborn as sns
</code></pre>

<p><strong><em>Data Loading</em></strong></p>

<pre><code>import pandas as pd  

</code></pre>

<pre><code># From CSV
df = pd.read_csv(&quot;path&quot;)
# From Excel
df = pd.read_excel('/path')  
</code></pre>

<p><strong><em>Indexing</em></strong></p>

<pre><code># Set index
df = df.set_index('colName')
# loc works on labels in the index
s.loc[:3]
# iloc works on the positions in the index (so it only takes integers)
s.iloc[:3]
</code></pre>

<p><strong><em>Sorting</em></strong></p>

<pre><code># First c1, then c2
df = df.sort(['c1','c2'], ascending=[False,True])
</code></pre>

<p><strong><em>Dropping</em></strong></p>

<pre><code># Drop columns (axis=0: column-wise; axis=1: row-wise)
df = df.drop(['Cabin','Ticket'],axis = 1)
# Drop rows
df = df.drop(['label string']) # by index name
df.drop(df.index[[1,3]]) # by row number (0-based)
</code></pre>

<p><strong><em>Slicing</em></strong></p>

<pre><code># Filter the dataset by a certain condition
df = df[df.name != 'Tina']
</code></pre>

<p><strong><em>Dealing with missings</em></strong></p>

<pre><code># Drop them
df = df.dropna()
# Fill them
df.fillna(0) # fill by a number
df.fillna(method='ffill') # propagates last valid observation forward to next valid
df.fillna(method='bfill')
</code></pre>

<p><strong><em>Sampling</em></strong></p>

<pre><code>df_GM_sample = df_GM.sample(n=None, frac=None)
</code></pre>

<p><strong><em>Apply function</em></strong></p>

<pre><code># axis=0: column-wise; axis=1: row-wise
df.apply(func,axis = )
# apply to every element
df.applymap(lambda x: )
</code></pre>

<p><strong><em>Dealing with datetime</em></strong></p>

<pre><code># string to datetime
df.dt = pd.to_datetime(df.dt, format='%Y%m%d')

# get datetime indexes
t = pd.DatetimeIndex(df.dt)
hr = t.hour
df['HourOfDay'] = hr
month = t.month
df['Month'] = month
year = t.year
df['Year'] = year

# resample time series
df = df.set_index('datetime')
weekly_summary['speed'] = df.speed.resample('W').mean()
weekly_summary['distance'] = df.distance.resample('W').sum()
weekly_summary['cumulative_distance'] = df.cumulative_distance.resample('W').last()

# generate given format string from datetime
df['DOB1'] = df['DOB'].dt.strftime('%m/%d/%Y')
</code></pre>

<p><strong><em>Categorical to dummy</em></strong></p>

<pre><code>dummiesT = pd.get_dummies(test['Embarked'],prefix = 'Embarked')
test = pd.concat([test,dummiesT],axis = 1)
test = test.drop('Embarked',axis =1)
</code></pre>

<p><strong><em>concat &amp; join</em></strong></p>

<pre><code># concat along rows
df_new = pd.concat([df_a, df_b])

# join
df = df1.join(df2, how='left', lsuffix='', rsuffix='', sort=False)
</code></pre>

<p><strong><em>Groupby</em></strong></p>

<pre><code>df.groupby(by = 'Sex').mean()
</code></pre>

<p><strong><em>Differencing &amp; Cumulation</em></strong></p>

<pre><code># Differencing
data['instantaneous'] = data.volume_out.diff()

# Cumulation
consum.loc[:,&quot;group&quot;] = consum[&quot;is_start_point&quot;].cumsum()
</code></pre>

<p><strong><em>Sliding Window Apply</em></strong></p>

<pre><code>df[&quot;is_lucky_than_previous&quot;] =\
pd.rolling_apply(df.Survived, 2, lambda x: x[1] - x[0] == 1).fillna(1)
</code></pre>

<p><strong><em>Regular Expression</em></strong></p>

<pre><code> def volCalc(row):
    name = row['tbordername']
    try:
        vol = 0
        p = re.compile(r'(\d+)ml')
        sizes = p.findall(name)
        for size in sizes:
            p1 = re.compile(size + r'ml\D+(\d)\D+')
            amount = p1.findall(name)
            if amount:
                vol += int(size)*int(amount[0])
            else:
                vol += int(size)*1
        return vol
    
    except:
        return 'N/A'
</code></pre>

<h3 id="descriptive-stats:f1e1a77f1615c44bf32d0a2ae6e592a4">Descriptive Stats</h3>

<hr />

<p><strong><em>Numerical stats</em></strong></p>

<pre><code>df.describe()
</code></pre>

<p><strong><em>Correlation</em></strong></p>

<pre><code>corr = df.corr()
plt.matshow(df.corr())
</code></pre>

<p><strong><em>Basic Charts</em></strong></p>

<pre><code># line chart
fig = plt.figure(figsize=(12,6))
plt.plot(data.dateTime,data.volume_out)
plt.title('title')

# hist: numerical feature distribution
df.Age.hist()
# categorical feature distribution  
df.Survived.value_counts().plot(kind = 'bar')
# Basic box plot
sns.boxplot(consum.instantaneous,orient='v')
plt.title('instantaneous consumption value distribution')
# Box plot with hue
sns.boxplot(x=&quot;Sex&quot;, y=&quot;Age&quot;,hue = 'Survived', data=df, palette=&quot;Set3&quot;)

# Scatter
plt.scatter(df.Fare,df.Survived)
plt.xlabel('Fare')
plt.ylabel('Survived?')

# Regression chart
sns.jointplot(x=&quot;duration&quot;, y=&quot;usage&quot;, kind = 'reg', data=filtered)
plt.title('title')


</code></pre>

<h3 id="feature-engineering:f1e1a77f1615c44bf32d0a2ae6e592a4">Feature Engineering</h3>

<hr />

<p><strong><em>Rescaling</em></strong></p>

<pre><code># (0,1) scaling 
# (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
cols_to_norm = ['PassengerId','SibSp']
df[cols_to_norm] = df[cols_to_norm].apply(lambda x: scaler.fit_transform(x))

# Standardization: Zero mean and unit variance
from sklearn.preprocessing import scale
cols_to_norm = ['Age','SibSp']
df[cols_to_norm] = df[cols_to_norm].apply(lambda x: scale(x))

# Normalization: scaling individual observation (row) to have unit norm.
# if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples, like KNN. 
from sklearn.preprocessing import normalize
df_normalized = pd.DataFrame(normalize(df._get_numeric_data(),norm = 'l2'),columns=df._get_numeric_data().columns,index=df._get_numeric_data().index)
df_normalized.apply(lambda x: np.sqrt(x.dot(x)), axis=1) # check results
</code></pre>

<p><strong><em>Feature Binarization</em></strong></p>

<pre><code># thresholding numerical features to get boolean values
from sklearn.preprocessing import Binarizer
binarizer = Binarizer(threshold=30)
df['Age'] = df['Age'].apply(lambda x: binarizer.fit_transform(x)[0][0])
</code></pre>

<p><strong><em>Generating Polynomial Features</em></strong></p>

<pre><code># get features’ high-order and interaction terms
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(2)
#  (X_1, X_2) to (1, X_1, X_2, X_1^2, X_1X_2, X_2^2)
X_poly = pd.DataFrame(poly.fit_transform(X))
</code></pre>

<h3 id="feature-selection:f1e1a77f1615c44bf32d0a2ae6e592a4">Feature Selection</h3>

<hr />

<p><strong><em>Filter methods</em></strong></p>

<pre><code># Variance Treshhold
from sklearn.feature_selection import VarianceThreshold 

# Univariate feature selection 
X_new = SelectKBest(chi2, k=2).fit_transform(X, y)
</code></pre>

<p><strong><em>Wrapper Methods</em></strong></p>

<pre><code># LASSO
class sklearn.linear_model.Lasso()

# Tree-based
class sklearn.ensemble.RandomForestClassifier()
</code></pre>

<h3 id="algorithm:f1e1a77f1615c44bf32d0a2ae6e592a4">Algorithm</h3>

<hr />

<p><a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/"><strong><em>Sk-Learn Official Cheat Sheet</em></strong></a>
<div  align="center"><br />
<img src="http://7xro3y.com1.z0.glb.clouddn.com/sklearncs.png" align=center width = "800" height = "500"/><br />
</div></p>

<p><strong><em>Frequent Used Pieces</em></strong></p>

<p><strong><em>Linear Regression</em></strong></p>

<pre><code>from sklearn import linear_model
# Create linear regression object
regr = linear_model.LinearRegression(fit_intercept=True)
# Train the model using the training sets
regr.fit(df, y)
# The coefficients
print('Coefficients:', regr.coef_)
# The mean squared error
print(&quot;Mean squared error: %.2f&quot;
      % np.mean((regr.predict(df) - y) ** 2))
# Explained variance score: 1 is perfect prediction
print &quot;R Squared score:&quot;;regr.score(df, y)

# Coef_ check
plt.figure(figsize=(12,8))
plt.barh(range(len(regr.coef_)),regr.coef_,height=0.2,tick_label = df.columns)
plt.title('Regression Coefficients')

# Residuals Check
res = regr.predict(df) - y
plt.axhline(0)
plt.scatter(range(len(res)),res.values,color = 'r')
plt.title('Residual Plot')
</code></pre>

<p><strong><em>Kmeans</em></strong></p>

<pre><code>from sklearn.cluster import KMeans
estimator = KMeans(n_clusters=3)
estimator.fit(filtered_scaled)
labels = estimator.labels_
</code></pre>

<p><strong><em>Random Forest</em></strong></p>

<pre><code>from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
rf = RandomForestClassifier(n_estimators=8000,n_jobs=-1,oob_score=True)
rf.fit(train,res)
rf.oob_score_
# feature importance
feature_importances = pd.Series(rf.feature_importances_,index = train.columns)
feature_importances.sort(inplace = True)
feature_importances.plot(kind = 'barh')
</code></pre>

<p><strong><em><a href="https://turi.com">Recommender</a></em></strong></p>

<pre><code># item-based CF
import graphlab
train_data = graphlab.SFrame(df_CF)
item_sim_model = graphlab.item_similarity_recommender.create(train_data, user_id='Customer_id', item_id='item')
# Make Recommendations
item_sim_recomm = item_sim_model.recommend(users=['5208494361'],k=10)
item_sim_recomm.print_rows()
</code></pre>

<p><strong><em>Time Series</em></strong></p>

<pre><code># DF Test
from statsmodels.tsa.stattools import adfuller
def test_stationarity(timeseries):
    
    # Determing rolling statistics
    rolmean = pd.rolling_mean(timeseries, window=10)
    rolstd = pd.rolling_std(timeseries, window=10)

    # Plot rolling statistics:
    plt.figure(figsize=(14,8))
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    
    plt.legend(loc='best')
    plt.title('Rolling Mean &amp; Standard Deviation')
    plt.show(block=False)
    
    # Perform Dickey-Fuller test:
    print 'Results of Dickey-Fuller Test:'
    dftest = adfuller(timeseries.SALES_IN_ML, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print dfoutput
</code></pre>

<pre><code># ARIMA
# Ordering: ACF and PACF plots
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plot_acf(TS_log, lags=30)
plot_pacf(TS_log, lags=30)

# Ordering: AIC
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.stattools import arma_order_select_ic
# Smaller Better
arma_order_select_ic(TS_log, max_ar=4, max_ma=0, ic='aic')

# Modeling
model = ARIMA(TS_log, order=(1, 0, 0))  
results_AR = model.fit(disp= 1)  
plt.plot(TS_log)
plt.plot(results_AR.fittedvalues, color='red')
TS_fitted = pd.DataFrame(results_AR.fittedvalues,columns=['SALES_IN_ML'])

# Residual Series Check
residuals = TS_log - TS_fitted
test_stationarity(residuals)
</code></pre>

<h3 id="tuning-validation:f1e1a77f1615c44bf32d0a2ae6e592a4">Tuning &amp; Validation</h3>

<hr />

<p><strong><em>Training/Test split</em></strong></p>

<pre><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)
</code></pre>

<p><strong><em>Cross Validation</em></strong></p>

<pre><code>from sklearn.model_selection import cross_val_score
from sklearn import svm
clf = svm.SVC(kernel='linear', C=1)
scores = cross_val_score(clf, X.values, y[0].values, cv=5)
# 95% confidence interval of the score
print(&quot;Accuracy: %0.2f (+/- %0.2f)&quot; % (scores.mean(), scores.std() * 2))
</code></pre>

<p><strong><em>Exhaustive Grid Search</em></strong></p>

<pre><code>from sklearn.model_selection import GridSearchCV
svr = svm.SVC()
parameters = {'kernel':('linear','rbf'), 'C':[1, 10]}
clf = GridSearchCV(svr, parameters,n_jobs = -1,cv = 5)
clf.fit(X, y[0])
clf.cv_results_
clf.best_estimator_
</code></pre>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="http://xren615.github.io/post/feature_reducing/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="http://xren615.github.io/post/feature_reducing/">特征选择：一份简明指南</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
  </div>
</div>



  
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'xren615';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>

</div>
</div>
<script src="http://xren615.github.iojs/ui.js"></script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-76515451-1', 'auto');
  ga('send', 'pageview');

</script>



</body>
</html>

