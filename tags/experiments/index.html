<!DOCTYPE html>
<html>

<head>
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-76515451-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-76515451-1');
  </script>
  

  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>Experiments  &middot; INCH2</title>
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
  <link rel="canonical" href="http://xren615.github.io/tags/experiments/">
  
  <link href="http://xren615.github.io/tags/experiments/index.xml" rel="alternate" type="application/rss+xml" title="Experiments" />
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css">
  <link rel="stylesheet" href="/css/styles.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<body>
  <div class="navbar">
    <ul>
      <li><a href="/" class="logo-title">HELLO,WORLD!</a></li>
      <li><a href="/categories">CATEGORIES</a></li>
      <li><a href="/tags">TAGS</a></li>
    </ul>
  </div>
  <div class="container">
    <div class="title">
      <a href="/">
        <img src="/images/logo.png" width="260px" height="48px" />
      </a>
    </div>



  <a href="http://xren615.github.io/post/experiment/">
  <div class="post-title">
    <img src="/images/post-title-icon.png" />
    <div class="post-meta">
      <time>13 Apr 2018, 01:30</time>
      <h1>Random thoughts on A/B testing at LinkedIn</h1>
    </div>
  </div>
</a>
<div class="summary-content">
  写在前面
Random thoughts about A/B testing came into my mind while working at LinkedIn.
A/B测试正被越来越多的公司和科研机构使用，它能让决策告别『拍脑袋』，以实际的试验结果对比展示各个方案间的取舍，从而实现数据驱动的决策。LinkedIn作为业界最早以及最广泛使用A/B测试的科技公司之一，在方法论和工程实现上都有丰富的积累。本篇文章并非对其完整地论述，而是在日常工作中产生的随机总结和思考。
 Statistical ABC 本章节分级总结A/B测试的统计学基础。简单明了为先，严谨其次。
LEVEL1: 告别『拍脑袋』
这是树立数据驱动思想的第一步：开发者和产品经理都开始意识到，小至用绿色图标还是红色图标，大到内容流的构成和排序，都不能以『拍脑袋』的方式来决定：这种方法并不能帮助他们找到最优解，且倘若彼此意见不一致，彼此都很难说服对方。
于是他们产生了朴素的想法：给一半人展示绿色图标，同时给另一半人展示红色图标，然后比较两组试验的表现 —— 这就是A/B测试的基本思想。这样一来，A/B测试不仅可以回答『哪种方案更好？』而且可以通过比较定量地分析『好多少？』
LEVEL2: 我的差异显著吗
现在通过试验，产品经理喜爱的绿色和工程师喜爱的红色页面拥有了不同的表现数据。譬如点击率（CTP）对比是10% vs. 11% —— 那么，这足以说明后者更受用户欢迎吗？
除了关心试验数据本身，我们还需要考虑A/B测试结果中产生的组间差异有多大可能来自于随机误差。试想，同样是10% vs. 11%，10/100 vs. 11/100的说服力与1000/10000 vs. 1100/10000的说服力一样吗？直觉告诉我们，样本高达10000时显示出的1%差异似乎更有说服力，而100样本量实验中的仅仅1个转化的差异似乎有更大的可能来自于随机误差。
换而言之，在产品决策者做出决定之前，不仅需要知道实验组与对照组对比表现有多大提升，同时也需要知道观察到的提升有多大可能是来源于试验中的随机误差。
统计学中的假设检验理论为我们提供了量化这种可能性的方法。暂时略去其背后的理论体系，从实用的角度看，现在任何成熟的A/B测试系统都会随着试验结果一并给出一个叫做p-value的统计量，它将告诉我们两组实验数据的差异来自于随机误差的概率。一般地，行业标准可以接受的p-value范围是 &lt;=0.05，换而言之，我们至少有95%的信心推断实验数据的差异确实来源于产品改动而非随机误差 —— 这时我们称组间差异是统计显著的。
LEVEL3 计算关键指标
对于不专门从事数据工作的职位，理解LEVEL2 已经达到了了解A/B测试的基础目标。然而数据分析师仍需要知其所以然，掌握各个关键指标背后的统计计算逻辑，才能有理有据地对实验数据进行详细分析。
仍然以点击率（CTP）为例，假设我们已知实验组的样本总量和点击量分别为（Nt, Xt），对照组的样本总量和点击量分别为（Nc, Xc），如何评价本次试验的显著性？
首先，可以很直观地计算出两个组别在实验中的点击率
$$Pt = \frac {Nt}{Xt} \quad and \quad Pc = \frac {Nc}{Xc}$$
我们进行原假设为『实验组和对照组的点击率没有明显差别』的假设检验，即 $$H_0: Pt - Pc = 0$$
  
  <a href="/post/experiment/" class="summary-more">READ MORE</a>
  
</div>
  <hr class="summary-sep" />


<div class="paging">
  
  PAGE 1 / 1
  
</div>

<footer class="footer">
  COPYRIGHT (C) <a href="https://blog.lulab.net">DONGGEUN,BANG</a>. ALL RIGHTS RESERVED.
</footer>

</body>
</html>

